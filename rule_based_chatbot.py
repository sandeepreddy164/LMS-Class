# -*- coding: utf-8 -*-
"""Rule_based_chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GLcuS52uR4vcpMWGw14B7zzWf8lVcCft
"""

import nltk
import re
from nltk.chat.util import Chat, reflections

pairs = [
    [r"my name is (.*)", ["Hello %1, how can I assist you today?",]],
    [r"hi|hey|hello", ["Hello, how can I help you?", "Hey there! What can I do for you?",
                       "Hi! How can I assist you today?"]],
    [r"what is your name?", ["I am a chatbot created to assist you. You can call me Chatbot.",]],
    [r"how are you?", ["I'm a bot, so I don't have feelings, but I'm here to help you!",]],
    [r"can you help me with (.*)", ["Sure, I can help you with %1. Please provide more details.",]],
    [r"sorry (.*)", ["It's okay. How can I assist you?",]],
    [r"thank you|thanks", ["You're welcome!", "No problem!", "Happy to help!"]],
    [r"quit", ["Bye! Have a great day!", "Goodbye!"]],
    [r"best places (.*)", ["Hyderabad","Banglore","Vizag", "Mumbai"]],
    [r"(.*)", ["I'm sorry, I don't understand that. Can you rephrase?",
               "Could you please elaborate on that?"]]
]

class RBChatbot:
  def __init__(self, pairs):
    self.chat = Chat(pairs, reflections)

  def respond(self, user_input):
    return self.chat.respond(user_input)

chatbot = RBChatbot(pairs)

def chat_with_bot():
  print("Hi, I'm a chatbot. Type 'quit' to exit")
  while True:
    user_input = input("You: ")
    if user_input.lower() == "quit":
      print("Chatbot: Bye!Have a great day!")
      break
    response = chatbot.respond(user_input)
    print("Chatbot:", response)

chat_with_bot()

pip install transformers torch

from transformers import BertForQuestionAnswering, BertTokenizer
import torch
# Load pre-trained BERT model and tokenizer
model_name = "deepset/bert-base-cased-squad2"  # BERT trained on SQuAD 2.0
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForQuestionAnswering.from_pretrained(model_name)

context = """The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.
It is named after the engineer Gustave Eiffel, whose company designed and built the tower."""
question = "Who designed the Eiffel Tower?"
inputs = tokenizer(question, context, return_tensors="pt")
with torch.no_grad():
    outputs = model(**inputs)
    start_scores = outputs.start_logits
    end_scores = outputs.end_logits

start_idx = torch.argmax(start_scores)
end_idx = torch.argmax(end_scores) + 1
answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs["input_ids"][0][start_idx:end_idx]))
print(f"Answer: {answer}")

context1 ="Coronavirus disease 2019 (COVID-19, also known as SARS-2) is a contagious disease caused by the coronavirus SARS-CoV-2. In January 2020, the disease spread worldwide, resulting in the COVID-19 pandemic."
question1 = "what is the cause for coronavirus?"
inputs = tokenizer(question1, context1, return_tensors="pt")
with torch.no_grad():
    outputs = model(**inputs)
    start_scores = outputs.start_logits
    end_scores = outputs.end_logits
start_idx = torch.argmax(start_scores)
end_idx = torch.argmax(end_scores) + 1
answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs["input_ids"][0][start_idx:end_idx]))
print(f"Answer: {answer}")

